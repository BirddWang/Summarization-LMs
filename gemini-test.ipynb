{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from secret import GEMINI_API_KEY\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_settings = [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gemini(DeepEvalBaseLLM):\n",
    "    \"\"\"Class to implement Vertex AI for DeepEval\"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = genai.GenerativeModel(model)\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        summary_model = self.load_model()\n",
    "        return summary_model.generate_content(\n",
    "            contents=prompt,\n",
    "            generation_config={'candidate_count': 1, 'temperature': 0.0}, \n",
    "            safety_settings=safety_settings\n",
    "        ).text\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        summary_model = self.load_model()\n",
    "        res = await summary_model.generate_content(\n",
    "            contents=prompt,\n",
    "            generation_config={'candidate_count': 1, 'temperature': 0.0}, \n",
    "            safety_settings=safety_settings\n",
    "        )\n",
    "        return res.text\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Gemini AI Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model_gemini = Gemini(\n",
    "    model=\"gemini-1.5-flash-latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.metrics import GEval\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_metric = GEval(\n",
    "    name=\"Consistency\",\n",
    "    criteria = \"the factual alignment between the summary and the summarized source. A factually consistent summary contains only statements that are entailed by the source document. Annotators were also asked to penalize summaries that contained hallucinated facts.\",\n",
    "    evaluation_steps=[\n",
    "        \"Read the news article carefully and identify the main facts and details it presents.\",\n",
    "        \"Read the summary and compare it to the article. Check if the summary contains any factual errors that are not supported by the article.\",\n",
    "        \"Assign a score for consistency based on the Evaluation Criteria.\"\n",
    "    ],\n",
    "    model=Gemini('gemini-1.5-flash-latest'),\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    async_mode=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = 'data/cnndm_sumllm/gpt4/train.jsonl'\n",
    "store_dir = 'data/cnndm_sumllm/gpt4/gemini-consistency_results.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(src_dir, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for (i, line) in enumerate(lines):\n",
    "        data = json.loads(line)\n",
    "        test_case = LLMTestCase(\n",
    "            input=data['article'],\n",
    "            actual_output=data['abstract']\n",
    "        )\n",
    "        time.sleep(3)\n",
    "        try:\n",
    "            consistency_metric.measure(test_case=test_case)\n",
    "        except Exception as e:\n",
    "            print(\"wait for 10 seconds\")\n",
    "            time.sleep(10)\n",
    "            try:\n",
    "                consistency_metric.measure(test_case=test_case)\n",
    "            except Exception as e:\n",
    "                print(\"wait for 20 seconds\")\n",
    "                time.sleep(20)\n",
    "                try:\n",
    "                    consistency_metric.measure(test_case=test_case)\n",
    "                except Exception as e:\n",
    "                    print('the load is too high, please try again later')\n",
    "                    break\n",
    "        with open(store_dir, 'a') as f2:\n",
    "            f2.write(json.dumps({\n",
    "                'score': consistency_metric.score,\n",
    "                'reason': consistency_metric.reason\n",
    "            }) + '\\n')\n",
    "        if i==10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
